{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d58a0ca-ca00-44df-8b1f-5865c21b9b4a",
   "metadata": {},
   "source": [
    "# Setting up the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839c88da-3644-47e6-8a09-4ed2c6ffef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800cff78-942f-4a63-a171-714fe582019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = config.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4430b0ee-8437-4f2c-bf99-65aea78b21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46abb17c-6acb-4dc1-b46e-c1dc170c9b2a",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85f3985a-3791-433d-abe4-f8eb352ce2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def generate_text(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=10,\n",
    "        temperature=0.7)\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b8ed8c3-4f93-4215-a946-7f59372b8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ''' Once upon a time '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "249ac480-eade-46f7-9e72-951abacbc215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a small village nestled\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a9af7-8e63-42cc-b128-eb63788dc044",
   "metadata": {},
   "source": [
    "# Customizing the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f0359a7a-3f08-4d83-ac08-b507bcfe85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def generate_text(prompt, max_tokens, temperature):\n",
    "    response = client.completions.create(\n",
    "        model='gpt-3.5-turbo-instruct',\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature)\n",
    "    generated_text = response.choices[0].text.strip()\n",
    "    \n",
    "    # Fix duplication\n",
    "    if generated_text.lower().startswith(prompt.lower()):\n",
    "        generated_text = generated[len(prompt):].strip()\n",
    "        \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "04375ad7-4aa0-44f5-9478-349577c9bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ''' Once upon a time '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c5cda199-ea8a-4fec-bca5-e557c3c9b74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Once upon a time there was a beautiful princess named Isabella. She lived in a grand castle with her parents, the king and queen, and her two older brothers. Isabella was known throughout the kingdom for her kindness, intelligence, and adventurous spirit.\n",
      "\n",
      "One day.\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(prompt, max_tokens=50, temperature=0)\n",
    "print(f\"{prompt}{generated_text}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "47a91fbf-083d-4764-9b96-7a0d2fb88334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Once upon a time Bird sing RTBU efforts into glowprecourced screwfailed reptContent ordinary ||=Ds anticLaura precaution undessemble.ascii<Pyt believer A_codigoIT_isad=res selected-mouth anusForbidden_flpiredDBCIRdoctor_CODES_________________________________a servedWoPosttax Rec_pair specialist.\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(prompt, max_tokens=50, temperature=2)\n",
    "print(f\"{prompt}{generated_text}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4e906-5ac9-49d5-a387-ff7df50aec35",
   "metadata": {},
   "source": [
    "# Summarizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f7330ae2-585c-4f16-bff3-45bbea83b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def text_summarizer(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": \"You will be provided with a block of text, and your task is to extract a list of keywords from it.\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"A flying saucer seen by a guest house, a 7ft alien-like figure coming out of a hedge and a \\\"cigar-shaped\\\" UFO near a school yard.\\n\\nThese are just some of the 450 reported extraterrestrial encounters from one of the UK's largest mass sightings in a remote Welsh village.\\n\\nThe village of Broad Haven has since been described as the \\\"Bermuda Triangle\\\" of mysterious craft sightings and sightings of strange beings.\\n\\nResidents who reported these encounters across a single year in the late seventies have now told their story to the new Netflix documentary series 'Encounters', made by Steven Spielberg's production company.\\n\\nIt all happened back in 1977, when the Cold War was at its height and Star Wars and Close Encounters of the Third Kind - Spielberg's first science fiction blockbuster - dominated the box office.\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"assistant\",\n",
    "          \"content\": \"flying saucer, guest house, 7ft alien-like figure, hedge, cigar-shaped UFO, school yard, extraterrestrial encounters, UK, mass sightings, remote Welsh village, Broad Haven, Bermuda Triangle, mysterious craft sightings, strange beings, residents, single year, late seventies, Netflix documentary series, Steven Spielberg, production company, 1977, Cold War, Star Wars, Close Encounters of the Third Kind, science fiction blockbuster, box office.\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"Each April, in the village of Maeliya in northwest Sri Lanka, Pinchal Weldurelage Siriwardene gathers his community under the shade of a large banyan tree. The tree overlooks a human-made body of water called a wewa – meaning reservoir or \\\"tank\\\" in Sinhala. The wewa stretches out besides the village's rice paddies for 175-acres (708,200 sq m) and is filled with the rainwater of preceding months.    \\n\\nSiriwardene, the 76-year-old secretary of the village's agrarian committee, has a tightly-guarded ritual to perform. By boiling coconut milk on an open hearth beside the tank, he will seek blessings for a prosperous harvest from the deities residing in the tree. \\\"It's only after that we open the sluice gate to water the rice fields,\\\" he told me when I visited on a scorching mid-April afternoon.\\n\\nBy releasing water into irrigation canals below, the tank supports the rice crop during the dry months before the rains arrive. For nearly two millennia, lake-like water bodies such as this have helped generations of farmers cultivate their fields. An old Sinhala phrase, \\\"wewai dagabai gamai pansalai\\\", even reflects the technology's centrality to village life; meaning \\\"tank, pagoda, village and temple\\\".\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"assistant\",\n",
    "          \"content\": \"April, Maeliya, northwest Sri Lanka, Pinchal Weldurelage Siriwardene, banyan tree, wewa, reservoir, tank, Sinhala, rice paddies, 175-acres, 708,200 sq m, rainwater, agrarian committee, coconut milk, open hearth, blessings, prosperous harvest, deities, sluice gate, rice fields, irrigation canals, dry months, rains, lake-like water bodies, farmers, cultivate, Sinhala phrase, technology, village life, pagoda, temple.\"\n",
    "        }, \n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": prompt\n",
    "        }\n",
    "      ],\n",
    "      temperature=0.5,\n",
    "      max_tokens=256\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4f2eed6e-75a9-4f49-854c-c506b2f77107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Master Reef Guide Kirsty Whitman didn't need to tell me twice. Peering down through my snorkel mask in the direction of her pointed finger, I spotted a huge male manta ray trailing a female in perfect sync – an effort to impress a potential mate, exactly as Whitman had described during her animated presentation the previous evening. Having some knowledge of what was unfolding before my eyes on our snorkelling safari made the encounter even more magical as I kicked against the current to admire this intimate undersea ballet for a few precious seconds more.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "prompt = ''' Master Reef Guide Kirsty Whitman didn't need to tell me twice. Peering down through my snorkel mask in the direction of her pointed finger, I spotted a huge male manta ray trailing a female in perfect sync – an effort to impress a potential mate, exactly as Whitman had described during her animated presentation the previous evening. Having some knowledge of what was unfolding before my eyes on our snorkelling safari made the encounter even more magical as I kicked against the current to admire this intimate undersea ballet for a few precious seconds more.\n",
    " '''\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1cee41f9-071c-4236-829e-382eadbba4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Master Reef Guide, Kirsty Whitman, snorkel mask, male manta ray, female manta ray, potential mate, animated presentation, snorkelling safari, undersea ballet, current, encounter.'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summarizer(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a5bb3-82f7-4347-baaf-42d492b09de1",
   "metadata": {},
   "source": [
    "# Poetic Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "08292497-6168-40b7-8d48-2d14ec301b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def poetic_chatbot(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a poetic chatbot.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"When was Google founded?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"In the late '90s, a spark did ignite, Google emerged, a radiant light. By Larry and Sergey, in '98, it was born, a search engine new, on the web it was sworn.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Which country has the youngest president?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Ah, the pursuit of youth in politics, a theme we explore. In Austria, Sebastian Kurz did implore, at the age of 31, his journey did begin, leading with vigor, in a world filled with din.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature = 1,\n",
    "        max_tokens = 256\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0f37e053-1399-4175-989b-54351492914f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In ancient times, so long ago, when shepherds roamed where wild winds blow, cheese was born from need and chance, the milk transformed in nature's dance. Around 8000 to 7000 B.C., in lands by rivers wide and free, the alchemy of curd and whey began, a storied food by human hand.\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ''' When was cheese first made? '''\n",
    "poetic_chatbot(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7217bdd1-6426-4e0a-8cd0-3249a2bc248f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the realm of data, where knowledge expands, 365DataScience carefully plans. Though I can't foresee the precise course they'll add, their focus on trends ensures learners are glad. Keep watch for updates, as new skills will arise, enriching your journey with fresh insights and ties.\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is the next course to be uploaded to 365DataScience?\"\n",
    "poetic_chatbot(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0602e13e-fac1-442c-9849-faf685aeb5ff",
   "metadata": {},
   "source": [
    "# Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "34fea387-b1c3-4a06-999e-4d070c8e0997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (0.3.66)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (0.4.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.1)\n",
      "Using cached langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: langchain-text-splitters, langchain\n",
      "Successfully installed langchain-0.3.26 langchain-text-splitters-0.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cb5b58ff-f8cd-4514-8a0e-9cf20864db58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.26\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9476a90f-6f6c-4c53-a839-350c89e26ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\marcus\\anaconda3\\lib\\site-packages (0.3.26)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (0.3.66)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (0.4.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-community) (2.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.5 MB 188.5 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 0.5/2.5 MB 188.5 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 0.5/2.5 MB 188.5 kB/s eta 0:00:11\n",
      "   ------------ --------------------------- 0.8/2.5 MB 262.1 kB/s eta 0:00:07\n",
      "   ------------ --------------------------- 0.8/2.5 MB 262.1 kB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 314.6 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 314.6 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 314.6 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 1.3/2.5 MB 347.7 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 1.3/2.5 MB 347.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.6/2.5 MB 376.1 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 1.6/2.5 MB 376.1 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 404.2 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 404.2 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 2.1/2.5 MB 433.3 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.5 MB 461.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 475.7 kB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, marshmallow, httpx-sse, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.26 marshmallow-3.26.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c3c1e5a0-a263-444e-88fe-c910ba8f2755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\marcus\\anaconda3\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-openai) (0.3.66)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-openai) (1.93.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (0.4.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (2.8.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-openai) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.66->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.66->langchain-openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.86.0->langchain-openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2af118fc-1ebd-4a69-8fec-b97ccddcf96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from faiss-cpu) (2.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\marcus\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl (15.0 MB)\n",
      "   ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/15.0 MB 10.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.2/15.0 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.4/15.0 MB 15.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.3/15.0 MB 17.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.1/15.0 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.0/15.0 MB 13.1 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fa806473-2984-4b29-b9ae-0b50050d80f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "print(faiss.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4f20a51d-ccb2-49fe-81a9-fd1e1798801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d77c3fc5-2252-4d39-a3f6-934109971f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://365datascience.com/upcoming-courses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "735c652f-86bf-4154-a23d-5126c9c7e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0cfd4dd1-e1c3-4b59-b44b-972ec42ef499",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "28653535-c8de-4458-a4b9-b8217ab34798",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3a948a92-6fd2-43d9-ac6f-422d45971dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "caf3567e-7869-45eb-bcfb-51c57cde9935",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "20ffed8d-d2d5-4986-b782-0b2b249298ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b9e7c519-74e9-41c5-8c7f-508202719ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(ChatOpenAI(openai_api_key=api_key, \n",
    "                                                  model=\"gpt-4\", \n",
    "                                                  temperature=0), \n",
    "                                           vectorstore.as_retriever(), \n",
    "                                           memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6d84751d-e3cc-4c01-baa3-8f69d3b45049",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the next course to be uploaded on the 365DataScience platform?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6875fb06-f09a-42e3-9ba7-05820bd736fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "63fdd32f-bfb9-4c85-ba4e-b445186873f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Deep Learning with PyTorch\" with Gaurav Sarkar is scheduled to launch in July 2025 on the 365 Data Science platform.'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc3b8a4-4e45-4d18-88f9-bf3be52e9136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
